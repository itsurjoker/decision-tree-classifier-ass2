{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc795cec-5b1f-47e4-8d89-39da3fde4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Pairwise relationships using a pairplot\n",
    "sns.pairplot(data, hue=\"Outcome\", diag_kind='kde')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix heatmap\n",
    "correlation_matrix = data.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc09c71-48b6-4284-b8ad-4d93b61714e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Replace zero values with NaN in specific columns\n",
    "columns_to_replace = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "data[columns_to_replace] = data[columns_to_replace].replace(0, np.nan)\n",
    "\n",
    "# Box plots to detect outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']], palette=\"Set2\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939fc71-b7d2-4816-8b70-44bd684b0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the features (X) and the target variable (y)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# The random_state parameter ensures reproducibility by fixing the random seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4eb2b-cdfc-4b2f-a1c6-458f34c2697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the imputer (replace NaN values with the mean)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[('imputer', imputer), ('classifier', clf)])\n",
    "\n",
    "# Perform cross-validation to optimize hyperparameters\n",
    "param_grid = {\n",
    "    'classifier__max_depth': range(1, 11)  # Try different values for the maximum depth\n",
    "}\n",
    "\n",
    "# Perform 10-fold cross-validation to find the best max_depth\n",
    "cv_scores = []\n",
    "\n",
    "for max_depth in param_grid['classifier__max_depth']:\n",
    "    pipeline.set_params(classifier__max_depth=max_depth)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Find the max_depth that resulted in the highest cross-validated accuracy\n",
    "best_max_depth = param_grid['classifier__max_depth'][cv_scores.index(max(cv_scores))]\n",
    "\n",
    "# Train the final Decision Tree model with the best max_depth\n",
    "clf = DecisionTreeClassifier(max_depth=best_max_depth, random_state=42)\n",
    "\n",
    "# Fit the model using the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Now, your Decision Tree model is trained with the optimized hyperparameter and missing values handled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816cf76-807c-4992-88a0-9aefe2f9a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "y_probs = pipeline.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Labeling the plot\n",
    "classes = ['Non-Diabetic', 'Diabetic']\n",
    "tick_marks = range(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', color='white' if conf_matrix[i, j] > conf_matrix.max() / 2 else 'black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Visualize the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4dabe6-557a-4ada-86cf-f4bb91bf7abe",
   "metadata": {},
   "source": [
    "#Q6.\n",
    "\n",
    "Interpreting a decision tree involves examining the splits, branches, and leaves to understand how the model makes predictions. In your case, the decision tree is trained to predict whether a patient has diabetes based on clinical variables. To interpret the decision tree, we need to look at the splits and the most important variables along with their thresholds. Here's how you can interpret the decision tree:\n",
    "\n",
    "    Root Node: The root node represents the starting point of the decision tree. The variable and threshold used in the first split indicate the most important feature for making predictions.\n",
    "\n",
    "    Splits and Branches: As you traverse down the tree, you encounter splits and branches. Each split represents a decision point based on a specific variable, and each branch corresponds to one of the possible outcomes of that decision. The splitting criterion can be Gini impurity, entropy, or another metric, and the algorithm selects the variable and threshold that best separate the data into different classes.\n",
    "\n",
    "    Leaves: The terminal nodes of the tree are called leaves. Each leaf node is associated with a class label (0 for non-diabetic, 1 for diabetic). When a data point reaches a leaf, the model predicts the class label associated with that leaf.\n",
    "\n",
    "    Thresholds: For each split, you can find the threshold value that separates the data. The threshold represents a critical value of the variable used in the split. For example, if the first split occurs on the \"Glucose\" variable with a threshold of 140, it means that patients with glucose levels greater than 140 will follow one branch, while those with levels less than or equal to 140 will follow the other branch.\n",
    "\n",
    "    Important Variables: To identify the most important variables, you can look at the top-level splits and consider the features that appear early in the decision tree. These are typically the variables that have the most significant impact on the prediction.\n",
    "\n",
    "    Domain Knowledge and Common Sense: To interpret the patterns and trends, it's essential to use your domain knowledge and common sense. For example, if the first split is on the \"Glucose\" level, it's reasonable to expect that high glucose levels are a strong predictor of diabetes. Similarly, if the second split is on \"BMI,\" it suggests that the body mass index is another critical factor in diabetes prediction.\n",
    "\n",
    "    Pruning: Decision trees can become quite complex, and not all splits may be meaningful. Pruning techniques can be used to simplify the tree and remove unnecessary branches, making the interpretation more straightforward.\n",
    "\n",
    "It's essential to remember that decision trees are interpretable models, and understanding the splits, branches, and leaves can provide valuable insights into how the model is making predictions based on the given features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385963e5-783e-4108-bb2b-c3068f699c15",
   "metadata": {},
   "source": [
    "#Q7.\n",
    "\n",
    "Validating a decision tree model and testing its robustness to changes in the dataset or environment is a crucial step in the model development process. Here are some techniques, including sensitivity analysis and scenario testing, to explore uncertainty and risks:\n",
    "\n",
    "    Holdout Testing: Split your data into a training set and a holdout test set. Train the decision tree model on the training set and evaluate its performance on the holdout test set. This provides an estimate of how well the model generalizes to new, unseen data.\n",
    "\n",
    "    Cross-Validation: Use cross-validation techniques, such as k-fold cross-validation, to assess the model's performance more robustly. Cross-validation helps ensure that the model's performance is consistent across different subsets of the data.\n",
    "\n",
    "    Sensitivity Analysis:\n",
    "        Variable Importance: Analyze the importance of variables in the decision tree. Some libraries offer feature importance scores that can help you identify which features are most influential in making predictions.\n",
    "        Threshold Sensitivity: Evaluate how changes in the threshold values for splits affect the model's performance. You can increase or decrease the thresholds used in the decision tree splits to assess its sensitivity to these changes.\n",
    "\n",
    "    Scenario Testing:\n",
    "        Outliers: Test the model's robustness to outliers in the data. Introduce extreme values for certain variables and observe how the model responds. Outliers can significantly impact decision tree models.\n",
    "        Missing Data: Introduce missing values in the dataset and assess how the model handles missing data. You may need to preprocess the data to handle missing values, such as imputation or removal.\n",
    "        Feature Changes: Change the distribution of feature values to simulate different scenarios. For example, modify the distribution of glucose levels or age to see how the model's predictions change.\n",
    "        Concept Drift: If the environment or data distribution is subject to change over time, periodically retest the model's performance on new data to detect and adapt to concept drift.\n",
    "\n",
    "    Robustness Testing:\n",
    "        Perturbations: Introduce small random perturbations to the input features to test the model's stability. This can help identify whether the model is overly sensitive to noise in the data.\n",
    "        Model Variants: Compare the performance of the decision tree model to other models, such as random forests, gradient boosting, or support vector machines. Different models may have varying degrees of robustness.\n",
    "\n",
    "    Threshold Tuning: Experiment with changing the decision thresholds to balance precision and recall. This can be especially important in healthcare applications where the cost of false positives and false negatives may differ.\n",
    "\n",
    "    External Validation: If possible, obtain external datasets for validation. This can help ensure that the model performs consistently across different data sources and populations.\n",
    "\n",
    "    Business Impact Analysis: Consider the real-world impact of model predictions. For a healthcare application, assess how the model's predictions may affect patient care, costs, and outcomes.\n",
    "\n",
    "    Documentation and Monitoring: Continuously monitor the model's performance in production and document any observed deviations or issues. Implement feedback loops to retrain the model as needed.\n",
    "\n",
    "    Regulatory Compliance: Ensure that the model complies with any relevant regulatory requirements, especially in healthcare where patient data and decisions can have significant legal implications.\n",
    "\n",
    "By applying these techniques and conducting thorough validation and testing, you can better understand the performance and robustness of your decision tree model and mitigate potential risks and uncertainties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
